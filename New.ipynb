{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/dictionary.txt','r') as f:\n",
    "    dictionary_arr = [json.loads(part) for part in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headers': ['aba', 'abo'],\n",
       " 'entry': '<heading><strong>aba</strong></heading>, <heading><strong>abo</strong></heading>, <lang>свн.</lang> <lex>abe</lex> (нар.) <em>вниз, прочь, далеко</em>; <lex>aba</lex>, <lex>abe</lex>, <lex>ab</lex> (предл. с дат.) <em>с, от</em>, <lang>свн.</lang> <lex>abe</lex>, <lex>ab</lex>; <lang>нн.</lang> <lex>ab</lex>; <lang>дс.</lang> <lang>ди.</lang> <lang>го.</lang> <lex>af</lex>, <lang>да.</lang> <lang>а.</lang> <lex>of</lex>.',\n",
       " 'sources': [],\n",
       " 'other words': ['aba', 'abe', 'of', 'af', 'ab'],\n",
       " 'linked words': [],\n",
       " 'linked entries': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = {key: value for key, value in enumerate(dictionary_arr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headers': ['aba', 'abo'],\n",
       " 'entry': '<heading><strong>aba</strong></heading>, <heading><strong>abo</strong></heading>, <lang>свн.</lang> <lex>abe</lex> (нар.) <em>вниз, прочь, далеко</em>; <lex>aba</lex>, <lex>abe</lex>, <lex>ab</lex> (предл. с дат.) <em>с, от</em>, <lang>свн.</lang> <lex>abe</lex>, <lex>ab</lex>; <lang>нн.</lang> <lex>ab</lex>; <lang>дс.</lang> <lang>ди.</lang> <lang>го.</lang> <lex>af</lex>, <lang>да.</lang> <lang>а.</lang> <lex>of</lex>.',\n",
       " 'sources': [],\n",
       " 'other words': ['aba', 'abe', 'of', 'af', 'ab'],\n",
       " 'linked words': [],\n",
       " 'linked entries': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aba, abo, свн. abe (нар.) вниз, прочь, далеко; aba, abe, ab (предл. с дат.) с, от, свн. abe, ab; нн. ab; дс. ди. го. af, да. а. of.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('<.*?>','',dictionary_arr[0]['entry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in entries:\n",
    "    variants = set(entries[entry]['headers']+entries[entry]['other words'])\n",
    "    for var in variants:\n",
    "        maps[var].append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = dict(maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1393]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps['of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headers': ['ibu', 'ipu', 'ubi', 'obe'],\n",
       " 'entry': '<heading><strong>ibu</strong></heading>, <heading><strong>ipu</strong></heading>, <heading><strong>ubi</strong></heading>, <heading><strong>obe</strong></heading>, <lang>свн.</lang> <lex variants=\"obe, ob\">ob(e)</lex>, <lex>op</lex> (сз.) <em>если, как будто, хотя (и), ли</em>; <lang>нн.</lang> <lex>ob</lex>; <lang>дс.</lang> <lex>ef</lex>, <lex>of</lex>, <lang>ди.</lang> <lex>ef</lex>, <lang>го.</lang> <lex variants=\"ibai, iba\">iba(i)</lex>.',\n",
       " 'sources': [],\n",
       " 'other words': ['ef', 'iba', 'obe', 'op', 'ob', 'ibai', 'of'],\n",
       " 'linked words': [],\n",
       " 'linked entries': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[1393]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10648"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punkt = string.punctuation \n",
    "punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_json(arr, latin=[], rom=[], num=[], t=()):\n",
    "    result = []\n",
    "    for sentence in arr:\n",
    "        s = word_tokenize(sentence)\n",
    "        d = {'text':'', 'words':[]}\n",
    "        for word in s:\n",
    "            if word.startswith(t):\n",
    "                d['words'].append({'wf':word, 'wtype':'nontext'})\n",
    "            elif word in rom:\n",
    "                d['words'].append({'wf':word, 'wtype':'word', 'language':'rom'})\n",
    "            elif word in latin:\n",
    "                d['words'].append({'wf':word, 'wtype':'word', 'language':'latin'})\n",
    "            elif word in num:\n",
    "                d['words'].append({'wf':word, 'wtype':'num', 'language':'OHG'})\n",
    "            elif word in punkt:\n",
    "                d['words'].append({'wf':word, 'wtype':'punct'})\n",
    "            else:\n",
    "                if word in maps:\n",
    "                    d['words'].append({'wf':word, 'wtype':'word', 'language':'OHG', 'entry':maps[word]})\n",
    "                else:\n",
    "                    d['words'].append({'wf':word, 'wtype':'word', 'language':'OHG'})\n",
    "        text = ''\n",
    "        #print (self.doc['sentences'][k])\n",
    "        for key, word in enumerate(d['words']):\n",
    "            if 'wf' not in word:\n",
    "                continue\n",
    "            word['off_start'] = len(text)\n",
    "            if word['wtype'] == 'word':\n",
    "                text += word['wf'] + ' '\n",
    "                word['off_end'] = len(text) - 1\n",
    "            elif word['wtype'] == 'punctl':\n",
    "                text += word['wf']\n",
    "                word['wtype'] = 'punct'\n",
    "                word['off_end'] = len(text)\n",
    "            elif word['wtype'] == 'punctr':\n",
    "                if text.endswith(' '):\n",
    "                    word['off_start'] -= 1\n",
    "                    text = text[:-1]\n",
    "                text += word['wf'] + ' '\n",
    "                word['wtype'] = 'punct'\n",
    "                word['off_end'] = len(text) - 1\n",
    "            else:\n",
    "                if word['wf'].startswith(('(', '[', '{', '<', '“')):\n",
    "                    text += word['wf']\n",
    "                    word['off_end'] = len(text)\n",
    "                elif word['wf'].startswith((')', ']', '}', '>', '.', ':',',', '?', '!', '”', '…')):\n",
    "                    if text.endswith(' '):\n",
    "                        word['off_start'] -= 1\n",
    "                        text = text[:-1]\n",
    "                    text += word['wf'] + ' '\n",
    "                    word['off_end'] = len(text) - 1\n",
    "                else:\n",
    "                    text += word['wf'] + ' '\n",
    "                    word['off_end'] = len(text) - 1\n",
    "            word['sentence_index'] = key\n",
    "            word['next_word'] = key+1\n",
    "        d['text'] = text\n",
    "        result.append(d)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_return_text(meta, sep = '\\n', u = True):\n",
    "    text = open('./ahd-texts/texts/{}'.format(meta[0]),'r').read()\n",
    "\n",
    "    text = re.sub('<latin>\\n','\\n<latin>', text).strip()\n",
    "\n",
    "    latin = set(re.findall('<latin>(.*?)</latin>', text))\n",
    "    rom = set(re.findall('<rom>(.*?)</rom>', text))\n",
    "    num = set(re.findall('<num>(.*?)</num>', text))\n",
    "    if u: text = re.sub('\\n{2,}','\\n', text)\n",
    "    text = re.sub('(Verse): ([0-9]{1,3})',r'\\1_\\2', text)\n",
    "    arr = text.split(sep)\n",
    "    arr = [re.sub('<.*?>','', i).replace('\\n','').strip() for i in arr]\n",
    "    return arr, latin, rom, num\n",
    "\n",
    "def preprocess_and_save(meta, arr, latin, rom, num, t):\n",
    "    with open ('./ready_texts/{}'.format(meta[0]),'w') as f:\n",
    "        text = text_to_json(arr, latin, rom, t)\n",
    "        text = {'meta': {\n",
    "            'german_title': meta[1],\n",
    "            'russian_title':meta[2]\n",
    "        }, 'sentences':text}\n",
    "        json.dump(text, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = open('./ahd-texts/ahd_texts.csv','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['merseburger1.txt',\n",
       "  'Der Erste Merseburger Zauberspruch',\n",
       "  'Первое Мерзебургское заклинание'],\n",
       " ['merseburger2.txt',\n",
       "  'Der Zweite Merseburger Zauberspruch',\n",
       "  'Второе Мерзебургское заклинание'],\n",
       " ['hildebrandslied.txt', 'Das Hildebrandslied', 'Песнь о Хильтибранте'],\n",
       " ['wessobrunner.txt', 'Das Wessobrunner Gebet', 'Вессобруннская молитва'],\n",
       " ['isidor.txt', 'Der althochdeutsche Isidor', 'Древневерхненемецкий Исидор'],\n",
       " ['muspilli.txt', 'Muspilli', 'Mуспилли'],\n",
       " ['tatian.txt', 'Der althochdeutsche Tatian', 'Древневерхненемецкий Татиан'],\n",
       " ['eide.txt', 'Die Straßburger Eide ', 'Страсбургские клятвы'],\n",
       " ['evangelienbuch.txt', 'Otrfrids Evangelienbuch', 'Евангелие Отфрида'],\n",
       " ['ludwigslied.txt', 'Ludwigslied ', 'Песнь о Людвиге'],\n",
       " ['glossen.txt',\n",
       "  'Kasseler Glossen (Kasseler Gespräche)',\n",
       "  'Кассельские глоссы'],\n",
       " ['notker.txt',\n",
       "  'Notker - Boethius Consolatio philosophiae',\n",
       "  'Ноткер - Перевод Боэция - Утешение философией'],\n",
       " ['physyologus.txt', 'Der Ältere Physyologus', 'Старший Физиолог']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = [item.split(',') for item in total.split('\\n')]\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merseburger1\n",
    "k = 0\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n')\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merseburger2\n",
    "k = 1\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n')\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hildebrandslied\n",
    "k = 2\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n')\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wessobrunner\n",
    "k = 3\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n\\n', u=False)\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isidor\n",
    "k = 4\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n')\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Muspilli\n",
    "k = 5\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n')\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tatian\n",
    "k = 6\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n')\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eide\n",
    "k = 7\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n\\n', u = False)\n",
    "preprocess_and_save(total[7], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evangelienbuch\n",
    "k = 8\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n')\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ludwigslied\n",
    "k = 9\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n')\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glossen\n",
    "k = 10\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n')\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notker\n",
    "k = 11\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n')\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Physyologus\n",
    "k = 12\n",
    "arr, latin, rom, num = read_return_text(total[k], sep = '\\n')\n",
    "preprocess_and_save(total[k], arr, latin, rom, num, t=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
